# Домашнее задание

## Разворачиваем и настраиваем БД с большими данными

### 1. Выполним развертывание и предварительную настройку стенда для тестирования



### 1.1 Создадим две ВМ в конфигурации e2-standard-2 (2 CPU, 8GB RAM), 30 GB SDD.

#### 1.1.1 ВМ1

```
gcloud compute instances create instance-13-pg --project=postgres2021-lobach-02 --zone=us-central1-c --machine-type=e2-standard-2 --network-interface=network-tier=PREMIUM,subnet=default --maintenance-policy=MIGRATE --service-account=180845300769-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --create-disk=auto-delete=yes,boot=yes,device-name=instance-13-pg,image=projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20211212,mode=rw,size=30,type=projects/postgres2021-lobach-02/zones/us-central1-c/diskTypes/pd-ssd --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any

Created [https://www.googleapis.com/compute/v1/projects/postgres2021-lobach-02/zones/us-central1-c/instances/instance-13-pg].

WARNING: Some requests generated warnings:

- Disk size: '30 GB' is larger than image size: '10 GB'. You might need to resize the root repartition manually if the operating system does not support automatic resizing. See https://cloud.google.com/compute/docs/disks/add-persistent-disk#resize_pd for details.


NAME: instance-13-pg

ZONE: us-central1-c

MACHINE_TYPE: e2-standard-2

PREEMPTIBLE:

INTERNAL_IP: 10.128.0.14

EXTERNAL_IP: 104.198.170.232

STATUS: RUNNING

```

Убедимся, что размер раздела диска автоматически настроен на макcимальный размер:

```

OLobach@instance-13-pg:~$ df -h

Filesystem      Size  Used Avail Use% Mounted on

/dev/root        29G  1.7G   28G   6% /

devtmpfs        3.9G     0  3.9G   0% /dev

tmpfs           3.9G     0  3.9G   0% /dev/shm

tmpfs           796M  924K  795M   1% /run

tmpfs           5.0M     0  5.0M   0% /run/lock

tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup

/dev/loop0       56M   56M     0 100% /snap/core18/2253

/dev/loop1       62M   62M     0 100% /snap/core20/1270

/dev/loop2      253M  253M     0 100% /snap/google-cloud-sdk/208

/dev/loop3       44M   44M     0 100% /snap/snapd/14295

/dev/loop4       68M   68M     0 100% /snap/lxd/21835

/dev/sda15      105M  5.2M  100M   5% /boot/efi

tmpfs           796M     0  796M   0% /run/user/1003

 

```

### 1.1.2 ВМ2

```

gcloud compute instances create instance-13-ch --project=postgres2021-lobach-02 --zone=us-central1-c --machine-type=e2-standard-2 --network-interface=network-tier=PREMIUM,subnet=default --maintenance-policy=MIGRATE --service-account=180845300769-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --create-disk=auto-delete=yes,boot=yes,device-name=instance-13-pg,image=projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20211212,mode=rw,size=30,type=projects/postgres2021-lobach-02/zones/us-central1-c/diskTypes/pd-ssd --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any

```

### 1.2 На ВМ1 выполним установку Postgresql 14

```

sudo sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list' && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt -y update &&  sudo apt -y install postgresql-14

```
#### 1.2.2 Выполним настройку параметров Postgresql для оптимизации производительности (https://pgtune.leopard.in.ua/)

```

# DB Version: 14

# OS Type: linux

# DB Type: dw

# Total Memory (RAM): 8 GB

# CPUs num: 4

# Connections num: 20

# Data Storage: ssd

 
max_connections = 20

shared_buffers = 2GB

effective_cache_size = 6GB

maintenance_work_mem = 1GB

checkpoint_completion_target = 0.9

wal_buffers = 16MB

default_statistics_target = 500

random_page_cost = 1.1

effective_io_concurrency = 200

work_mem = 26214kB

min_wal_size = 4GB

max_wal_size = 16GB

max_worker_processes = 4

max_parallel_workers_per_gather = 2

max_parallel_workers = 4

max_parallel_maintenance_workers = 2

```

# 2 Выполним подготовку тестового набора данных в 10 GB из таблицы `bigquery-public-data.chicago_taxi_trips.taxi_trips

## 2.1 Оценим необходимое количество файлов CSV

```
Размер одного CSV-файла в бакете сотавляет 255.4 MB
Количество файлов N = 10*1024 / 255.4 = 40,09
```
## 2.2 Скопируем 40 файлов из бакета в файловую систему ВМ1:

```

postgres@instance-13-pg:/tmp/taxi_data$ gsutil -m cp -R gs://bigdata_hw13/taxi/taxi_0000000000[0-3]*.csv /tmp/taxi_data/

Copying gs://bigdata_hw13/taxi/taxi_000000000000.csv...

...

Copying gs://bigdata_hw13/taxi/taxi_000000000039.csv...B/s ETA 00:01:50

- [40/40 files][ 10.0 GiB/ 10.0 GiB] 100% Done   4.7 MiB/s ETA 00:00:00

Operation completed over 40 objects/10.0 GiB.

```

# 3 Выполним оценку времени обработки тестового набора данных в БД Postgresql

## 3.1 Создадим БД

```

postgres=# create database taxi;

CREATE DATABASE

```

## 3.2 Создадим таблицу

```

postgres=# \c taxi

You are now connected to database "taxi" as user "postgres".

taxi=# create table taxi_trips (

taxi(# unique_key text,

taxi(# taxi_id text,

taxi(# trip_start_timestamp TIMESTAMP,

taxi(# trip_end_timestamp TIMESTAMP,

taxi(# trip_seconds bigint,

taxi(# trip_miles numeric,

taxi(# pickup_census_tract bigint,

taxi(# dropoff_census_tract bigint,

taxi(# pickup_community_area bigint,

taxi(# dropoff_community_area bigint,

taxi(# fare numeric,

taxi(# tips numeric,

taxi(# tolls numeric,

taxi(# extras numeric,

taxi(# trip_total numeric,

taxi(# payment_type text,

taxi(# company text,

taxi(# pickup_latitude numeric,

taxi(# pickup_longitude numeric,

taxi(# pickup_location text,

taxi(# dropoff_latitude numeric,

taxi(# dropoff_longitude numeric,

taxi(# dropoff_location text

taxi(# );

CREATE TABLE

```

## 3.3 Загрузим данные с помощью команды COPY

```

postgres=# \timing

Timing is on.

```

```

taxi=# COPY taxi_trips(unique_key,

taxi(# taxi_id,

taxi(# trip_start_timestamp,

taxi(# trip_end_timestamp,

taxi(# trip_seconds,

taxi(# trip_miles,

taxi(# pickup_census_tract,

taxi(# dropoff_census_tract,

taxi(# pickup_community_area,

taxi(# dropoff_community_area,

taxi(# fare,

taxi(# tips,

taxi(# tolls,

taxi(# extras,

taxi(# trip_total,

taxi(# payment_type,

taxi(# company,

taxi(# pickup_latitude,

taxi(# pickup_longitude,

taxi(# pickup_location,

taxi(# dropoff_latitude,

taxi(# dropoff_longitude,

taxi(# dropoff_location)

taxi-# FROM PROGRAM 'awk FNR-1 /tmp/taxi_data/*.csv | cat' DELIMITER ',' CSV HEADER;

COPY 26066193

Time: 830634.380 ms (13:50.634)

```

## 3.4 Проведем оценку эффективности параллельного выполенения команды COPY для загрузки данных

### 3.4.1 Удалим и создадим таблицу taxi_trips;

```

taxi=# drop table taxi_trips ;

DROP TABLE

Time: 830.098 ms

 

taxi=# create table taxi_trips (

taxi(# unique_key text,

....

taxi(# );

CREATE TABLE

```

### 3.4.2 Запустим добавление данных в четырех параллельных процессах

```

postgres@instance-13-pg:/tmp$ date

Sun Jan  9 20:19:51 UTC 2022

postgres@instance-13-pg:/tmp$ cat copy_jobs | xargs -n1 -P4 -I% bash -c "%"

COPY 6560155

COPY 6486004

COPY 6483148

COPY 6536883

postgres@instance-13-pg:/tmp$ date

Sun Jan  9 20:35:43 UTC 2022

```

Содержимое скрипта copy_jobs:

```

postgres@instance-13-pg:/tmp$ cat copy_jobs

psql -U postgres taxi -c  \"COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) FROM PROGRAM \'awk FNR-1 /tmp/taxi_data/taxi_00000000000*.csv | cat\' DELIMITER \',\' CSV HEADER; \"

psql -U postgres taxi -c  \"COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) FROM PROGRAM \'awk FNR-1 /tmp/taxi_data/taxi_00000000001*.csv | cat\' DELIMITER \',\' CSV HEADER; \"

psql -U postgres taxi -c  \"COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) FROM PROGRAM \'awk FNR-1 /tmp/taxi_data/taxi_00000000002*.csv | cat\' DELIMITER \',\' CSV HEADER; \"

psql -U postgres taxi -c  \"COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) FROM PROGRAM \'awk FNR-1 /tmp/taxi_data/taxi_00000000003*.csv | cat\' DELIMITER \',\' CSV HEADER; \"

```

* Вывод:* Параллельное выполнение команды COPY на четырех ядрах заняло 15 минут 52 секунды, следовательно такой режим не стоит использовать для ускорения процесса наполнения БД, без дополнительных действий     

## 3.5 Проверим, что данные появились в таблице
```
                                     List of relations
Schema |    Name    | Type  |  Owner   | Persistence | Access method | Size  | Description

--------+------------+-------+----------+-------------+---------------+-------+-------------

public | taxi_trips | table | postgres | permanent   | heap          | 10 GB |

(1 row)

```

```

taxi=# select count(*) from taxi_trips;

  count

----------

26066190

(1 row)

 

Time: 389572.131 ms (06:29.572)
```
## 3.6 Оценим время выполнения эталонного запроса на тестовом наборе данных

```

taxi=# select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi_trips group by payment_type order by 3;

payment_type | tips_percent |    c

--------------+--------------+----------

Way2ride     |           15 |       92

Prepaid      |            0 |       96

Pcard        |            3 |     4997

Dispute      |            0 |    15478

Mobile       |           15 |    32805

Prcard       |            1 |    73698

Unknown      |            2 |    93546

No Charge    |            3 |   135208

Credit Card  |           17 | 10830145

Cash         |            0 | 14880125

(10 rows)

 

Time: 391130.826 ms (06:31.131)

```
## 3.7 Выполним оптимизацию запроса

### 3.7.1 Проведем анализ плана выполнения запроса

```
taxi=# explain(analyze, buffers) select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi_trips group by payment_type order by 3;
                                 QUERY PLAN                                                                        

---------------------------------------------------------------------------------------------------------------------------------------------------------------------

Sort  (cost=1698635.01..1698635.03 rows=9 width=47) (actual time=418561.240..418600.996 rows=10 loops=1)

   Sort Key: (count(*))

   Sort Method: quicksort  Memory: 25kB

   Buffers: shared hit=11 read=1391165

   ->  Finalize GroupAggregate  (cost=1698633.47..1698634.87 rows=9 width=47) (actual time=418561.105..418600.916 rows=10 loops=1)

         Group Key: payment_type

         Buffers: shared hit=8 read=1391165

         ->  Gather Merge  (cost=1698633.47..1698634.51 rows=9 width=79) (actual time=418560.949..418600.717 rows=20 loops=1)

               Workers Planned: 1

               Workers Launched: 1

               Buffers: shared hit=8 read=1391165

               ->  Sort  (cost=1697633.46..1697633.48 rows=9 width=79) (actual time=418536.727..418536.736 rows=10 loops=2)

                     Sort Key: payment_type
```
 

### 3.7.2 Для увеличения быстродействия запроса посторим b-tree индекс  и выполним повторный анализ плана выполнения запроса
```
taxi=# CREATE INDEX btree_taxi ON taxi_trips USING btree (payment_type,tips,trip_total);

CREATE INDEX

taxi=# explain(analyze, buffers) select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi_trips group by payment_type order by 3;
     QUERY PLAN                                                                

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Sort  (cost=566564.43..566564.45 rows=9 width=47) (actual time=10045.889..10087.586 rows=10 loops=1)

   Sort Key: (count(*))

   Sort Method: quicksort  Memory: 25kB

   Buffers: shared hit=749371 read=116029

   ->  Finalize GroupAggregate  (cost=1000.57..566564.29 rows=9 width=47) (actual time=9888.972..10087.549 rows=10 loops=1)

         Group Key: payment_type

         Buffers: shared hit=749371 read=116029

         ->  Gather Merge  (cost=1000.57..566563.93 rows=9 width=79) (actual time=5593.015..10087.363 rows=19 loops=1)

               Workers Planned: 1

               Workers Launched: 1

               Buffers: shared hit=749371 read=116029

               ->  Partial GroupAggregate  (cost=0.56..565562.91 rows=9 width=79) (actual time=5563.444..9964.886 rows=10 loops=2)

                     Group Key: payment_type
```
**Отмечаем заметное сокращение времени выполнения запроса.**

### 3.7.3 Чтобы исключить возможное влияние кэширования на результат, очистим кэш и проведем повторный анализ

#### 3.7.3.1 Очистка кэша файловой системы и кэша Postgresql

```

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main stop

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main status

pg_ctl: no server running

OLobach@instance-13-pg:~$ sudo sync

OLobach@instance-13-pg:~$ sudo su -

root@instance-13-pg:~# echo 3 > /proc/sys/vm/drop_caches

root@instance-13-pg:~# exit

logout

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main start

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main status

pg_ctl: server is running (PID: 1367)

/usr/lib/postgresql/14/bin/postgres "-D" "/var/lib/postgresql/14/main" "-c" "config_file=/etc/postgresql/14/main/postgresql.conf"

```
#### 3.7.3.2 Проведем повторный анализ плана запроса после очистки кэша

```
taxi=# explain(analyze, buffers) select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi_trips group by payment_type order by 3;

      QUERY PLAN                                                                 

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Sort  (cost=566564.43..566564.45 rows=9 width=47) (actual time=10801.017..10833.950 rows=10 loops=1)

   Sort Key: (count(*))

   Sort Method: quicksort  Memory: 25kB

   Buffers: shared hit=748914 read=116072

   ->  Finalize GroupAggregate  (cost=1000.57..566564.29 rows=9 width=47) (actual time=10625.849..10833.819 rows=10 loops=1)

         Group Key: payment_type

         Buffers: shared hit=748911 read=116072

         ->  Gather Merge  (cost=1000.57..566563.93 rows=9 width=79) (actual time=5905.654..10833.552 rows=19 loops=1)

               Workers Planned: 1

               Workers Launched: 1

               Buffers: shared hit=748911 read=116072

               ->  Partial GroupAggregate  (cost=0.56..565562.91 rows=9 width=79) (actual time=5882.074..10720.645 rows=10 loops=2)

                     Group Key: payment_type

                                                                              
```
**Отмечаем, что эффект заметного сокращения времени выполенения запроса сохранился после очистки кэша.**                                                                   


### 3.7.4 Выполним повторную оценку времени выполнения эталонного запроса

#### 3.7.4.1 Очищаем кэш

```

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main stop

OLobach@instance-13-pg:~$ sudo sync

OLobach@instance-13-pg:~$ sudo su -

root@instance-13-pg:~# echo 3 > /proc/sys/vm/drop_caches

root@instance-13-pg:~# exit

logout

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main start

OLobach@instance-13-pg:~$ sudo pg_ctlcluster 14 main status

pg_ctl: server is running (PID: 1506)

/usr/lib/postgresql/14/bin/postgres "-D" "/var/lib/postgresql/14/main" "-c" "config_file=/etc/postgresql/14/main/postgresql.conf"

```
#### 3.7.4.2 Включаем тайминг

```
taxi=# \timing

Timing is on.

```

#### 3.7.4.3 Повторно выполняем запрос

```

taxi=# select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi_trips group by payment_type order by 3;

payment_type | tips_percent |    c

--------------+--------------+----------

Way2ride     |           15 |       92

Prepaid      |            0 |       96

Pcard        |            3 |     4997

Dispute      |            0 |    15478

Mobile       |           15 |    32805

Prcard       |            1 |    73698

Unknown      |            2 |    93546

No Charge    |            3 |   135208

Credit Card  |           17 | 10830145

Cash         |            0 | 14880125

(10 rows)

 

Time: 8156.145 ms (00:08.156)

```

**Вывод: В результате оптимизации время выплнения запроса для тестового набора данных удалось сократить примерно в 48 раз: с 06 минут 31 секунд до 8 секунд**

 
# 3 Выполним оценку времени обработки тестового набора данных в СУБД СlickHouse
## 3.1 Установим СУБД ClickHouse в режиме standalone
```
sudo apt-get install apt-transport-https ca-certificates dirmngr
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4
echo "deb https://repo.clickhouse.com/deb/stable/ main/" | sudo tee  /etc/apt/sources.list.d/clickhouse.list
sudo apt-get update

sudo apt-get install -y clickhouse-server clickhouse-client

sudo service clickhouse-server start
clickhouse-client
```
## 3.2 Проверим статус сервиса
```
User@instance-13-ch:~$ sudo service clickhouse-server status
● clickhouse-server.service - ClickHouse Server (analytic DBMS for big data)
     Loaded: loaded (/etc/systemd/system/clickhouse-server.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2022-01-10 19:37:58 UTC; 4min 3s ago
   Main PID: 13940 (clckhouse-watch)
      Tasks: 205 (limit: 9536)
     Memory: 96.2M
     CGroup: /system.slice/clickhouse-server.service
             ├─13940 clickhouse-watchdog        --config=/etc/clickhouse-server/config.xml --pid-file=/run/clickhouse-server/clickhouse-server.pid
             └─13941 /usr/bin/clickhouse-server --config=/etc/clickhouse-server/config.xml --pid-file=/run/clickhouse-server/clickhouse-server.pid

Jan 10 19:37:58 instance-13-ch systemd[1]: Started ClickHouse Server (analytic DBMS for big data).
Jan 10 19:37:58 instance-13-ch clickhouse-server[13940]: Processing configuration file '/etc/clickhouse-server/config.xml'.
Jan 10 19:37:58 instance-13-ch clickhouse-server[13940]: Logging trace to /var/log/clickhouse-server/clickhouse-server.log
Jan 10 19:37:58 instance-13-ch clickhouse-server[13940]: Logging errors to /var/log/clickhouse-server/clickhouse-server.err.log
Jan 10 19:37:58 instance-13-ch clickhouse-server[13941]: Processing configuration file '/etc/clickhouse-server/config.xml'.
Jan 10 19:37:58 instance-13-ch clickhouse-server[13941]: Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/config.xml'.
Jan 10 19:37:58 instance-13-ch clickhouse-server[13941]: Processing configuration file '/etc/clickhouse-server/users.xml'.
Jan 10 19:37:58 instance-13-ch clickhouse-server[13941]: Merging configuration file '/etc/clickhouse-server/users.d/default-password.xml'.
Jan 10 19:37:58 instance-13-ch clickhouse-server[13941]: Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/users.xml'.

```
## 3.3 Создадим базу данных taxi
```
instance-13-ch.us-central1-c.c.postgres2021-lobach-02.internal :) CREATE DATABASE IF NOT EXISTS taxi

CREATE DATABASE IF NOT EXISTS taxi

Query id: d2b37e9a-e14e-435b-8005-6cd8613d391f

Ok.

0 rows in set. Elapsed: 0.005 sec.

```
## 3.4 Создадим таблицу taxi_trips со структурой, согласованной с форматом данных в csv-файлах
CREATE TABLE taxi.taxi_trips
(
    `unique_key` String,
    `taxi_id` String,
    `trip_start_timestamp` DateTime,
    `trip_end_timestamp` DateTime,
    `trip_seconds` Int64,
    `trip_miles` Decimal(10, 4),
    `pickup_census_tract` String,
    `dropoff_census_tract` String,
    `pickup_community_area` String,
    `dropoff_community_area` String,
    `fare` Decimal(10, 4),
    `tips` Decimal(10, 4),
    `tolls` Decimal(10, 4),
    `extras` Decimal(10, 4),
    `trip_total` Decimal(10, 4),
    `payment_type` String,
    `company` String,
    `pickup_latitude` Decimal(10, 4),
    `pickup_longitude` Decimal(10, 4),
    `pickup_location` String,
    `dropoff_latitude` Decimal(10, 4),
    `dropoff_longitude` Decimal(10, 4),
    `dropoff_location` String
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(trip_start_timestamp)
ORDER BY (payment_type, tips, tolls)

Query id: 464641b2-fc2e-43da-807d-1e4a69c4bcbf

Ok.

0 rows in set. Elapsed: 0.025 sec.

## 3.5 Добавим данные в созданную таблицу
### 3.5.1 Загрузим 10GB данных в локальную файловую систему из бакета в GCP
```
gsutil -m cp -R gs://bigdata_hw13/taxi/taxi_0000000000[0-3]*.csv ~/taxi_data/
Copying gs://bigdata_hw13/taxi/taxi_000000000000.csv...

...

Copying gs://bigdata_hw13/taxi/taxi_000000000039.csv...B/s ETA 00:01:53

- [40/40 files][ 10.0 GiB/ 10.0 GiB] 100% Done   4.7 MiB/s ETA 00:00:00

Operation completed over 40 objects/10.0 GiB.
```
### 3.5.2 Пробуем выполнить вставку данных из csv-файлов в созданную таблицу taxi_trips.
```
User@instance-13-ch:~$ cat ./taxi_data/*.csv | pv | clickhouse --client --password=123 --query 'INSERT INTO taxi.taxi_trips FORMAT CSVWithNames'
Code: 27. DB::ParsingException: Cannot parse input: expected ',' before: 'UTC,2015-08-26 11:15:00 UTC,0,0,,,,,5.85,1.46,0,0,7.31,Credit Card,Chicago Elite Cab Corp. (Chicago Carriag,,,,,,\n6d5b6e5f3e5397f08e770beeb5f34433b0491d12,c2ca6':
Row 1:
Column 0,   name: unique_key,             type: String,         parsed text: "3190243aa353d190bf2e5f366cd61617fa96f6a8"
Column 1,   name: taxi_id,                type: String,         parsed text: "9d4a0cf00e9283302f40800a5da6e7017db07876ff895d9a1ad185fb4b5ba4bc7263e79e5a073a5f147b0dcf5e1f9ce28e149227dcbbea09cc0262d1304b52bc"
Column 2,   name: trip_start_timestamp,   type: DateTime,       parsed text: "2015-08-26 11:15:00"
ERROR: There is no delimiter (,). "U" found instead.

: While executing CSVRowInputFormat: data for INSERT was parsed from stdin: (in query: INSERT INTO taxi.taxi_trips FORMAT CSVWithNames): (at row 1)
. (CANNOT_PARSE_INPUT_ASSERTION_FAILED)

 128KiB 0:00:00 [1.28MiB/s] [   <=>  
```
**Проблема:** 
В csv-файлах формат даты-времени отличается от формата, допустимого для ClickHouse - присутствует строка "UTC".
Допустимый формат имеет вид: _2015-08-26 11:15:00_. В csv-файлах данные о дате-времени присутсвуют в виде: _2015-08-26 11:15:00 UTC_
**Решение:**
В файлах с даными заменим подстроку "UTC," подстрокой "," 
### 3.5.3 Создадим скрипт для замены подстроки "UTC," подстрокой "," в файлах с расширением csv и выполним замену
```
User@instance-13-ch:~/taxi_data$ cat crop_utc
#!/bin/bash

EXT=csv
for i in *; do
    if [ "${i}" != "${i%.${EXT}}" ];then
        echo "Готовим файл  $i"
        awk '{sub(/UTC,/,",")}1' $i > temp.txt && mv temp.txt $i
        tail -n3 $i
    fi
done
```
Выполним замену подстроки:
```
User@instance-13-ch:~/taxi_data$ ./crop_utc
Готовим файл  taxi_000000000000.csv
0531f5700b93e55e93f76e7c0c9dbbd190c19883,0e0462dc8c7fe5581e3ed2e4bdce670e475dce86c46a01e5e0002b0f310d37bff086e286c54b13e12399ab5d986200a7c0911700c2d5e4230be48ccfeccf360d,2014-07-27 12:15:00 ,2014-07-27 13:00:00 ,2040,12.5,17031980000,17031040401,76,4,27.85,5.95,0,2,35.8,Credit Card,Taxi Affiliation Services,41.97907082,-87.903039661,POINT (-87.9030396611 41.9790708201),41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004)
55c5d6fe37dd0c1ccc9eec5853983324131c2528,0a5dfb0d81ebf2fc3e48921ca874c63dd8b31d3728d09adba2c923ed8b14064d0f36c4e6a3ab8f3e8202249dfa0002715a139ea0a28b260fea40cd5817d4f369,2014-08-02 01:00:00 ,2014-08-02 01:00:00 ,300,1.5,17031830700,17031040401,3,4,6.05,0,0,0,6.05,Cash,Choice Taxi Association,41.958055933,-87.660389456,POINT (-87.66038945570001 41.958055933),41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004)
e3ae1519417da37b6d639637ae8acedd155f2098,c8f57a1150c210a9e6b3fcfb24c3d6d0a43d1879b4b9795d12ffb5917f2b77c86a098c8f0a7c2a301ef4ea972985d4e05bd8d52a2f7a1ecca253fb8e81e5755e,2014-08-23 22:45:00 ,2014-08-23 23:00:00 ,420,0,17031050600,17031040401,5,4,6.45,0,0,1.5,7.95,Cash,Taxi Affiliation Services,41.950545696,-87.676182496,POINT (-87.6761824959 41.95054569650001),41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004)
...
Готовим файл  taxi_000000000039.csv
e311c770f133a6f406169ef797fcc5f577a2bec0,5381c356c596f1737ebdb3a346d03a8ea77a9ee429e7cddf174f34291b5c7ae671f4a3c13e9d66e0b244d3a042ee8d15ec80e36a2eb089fcda84114ff542069b,2013-07-05 23:30:00 ,2013-07-05 23:45:00 ,540,0,17031830700,17031040401,3,4,7.65,0,0,3,10.65,Cash,Taxi Affiliation Services,41.958055933,-87.660389456,POINT (-87.66038945570001 41.958055933),41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004)
4175031f29718a8313b27d257b8291a588040b19,028625a51564a7ae24bab0143aa1f7896bc798e0ae8e648369c826385f54a82988dc25d5bc124e7682e70f3014db4527a5b9d4e5a659390a06f68acdd9973e02,2013-06-29 03:15:00 ,2013-06-29 03:15:00 ,60,0.3,17031040401,17031040401,4,4,3.85,2,0,0,5.85,Credit Card,Northwest Management LLC,41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004),41.972035672,-87.686099898,POINT (-87.6860998978 41.972035672000004)
162dc650d9298284f034d507386bd0c3aeea00a2,62a7a216c1a01addeebe6ee75810d199ffa6cee3f4c23bc15be53f7814ad0243fa33a90cef81bc45c3ab57e9c17de8e8c3c99f4d3ec908598c482a89d8f616df,2013-06-28 12:00:00 ,2013-06-28 12:00:00 ,60,0,17031231500,17031231500,23,23,3.25,0,0,2,5.25,Cash,KOAM Taxi Association,41.891754203,-87.718670795,POINT (-87.7186707951 41.891754202600005),41.891754203,-87.718670795,POINT (-87.7186707951 41.891754202600005)

```

### 3.5.4 Создадим скрипт вставки данных из 40 csv-файлов в базу taxi_trips
```
User@instance-13-ch:~/taxi_data$ cat insert_data
#!/bin/bash

EXT=csv
for i in *; do
    if [ "${i}" != "${i%.${EXT}}" ];then
        echo "Вставляем данные из файла  $i"
        cat $i | clickhouse --client --password=123 --query 'INSERT INTO taxi.taxi_trips FORMAT CSVWithNames'
    fi
done

```

Выполняем вставку данных:
```
User@instance-13-ch:~/taxi_data$ ./insert_data
Вставляем данные из файла taxi_000000000000.csv
...


Вставляем данные из файла  taxi_000000000039.csv
```
### 3.5.5 Подключимся к СУБД СlickHouse и запросим количество записей, добавленных в таблицу taxi_trips 
```
instance-13-ch.us-central1-c.c.postgres2021-lobach-02.internal :) select count(*) from taxi.taxi_trips

SELECT count(*)
FROM taxi.taxi_trips

Query id: 977b2875-da9b-4cc7-92f5-81d7f31a8ba3

┌──count()─┐
│ 26066190 │
└──────────┘

1 rows in set. Elapsed: 0.004 sec.

```
# 3.6 Выполним оценку времени выполнения эталонного запроса
```
instance-13-ch.us-central1-c.c.postgres2021-lobach-02.internal :)  select payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c from taxi.taxi_trips group by payment_type order by 3

SELECT
    payment_type,
    round((sum(tips) / sum(trip_total)) * 100, 0) + 0 AS tips_percent,
    count(*) AS c
FROM taxi.taxi_trips
GROUP BY payment_type
ORDER BY 3 ASC

Query id: c32e1503-436a-4d1b-a4c5-acfac086e1ec

┌─payment_type─┬─tips_percent─┬────────c─┐
│ Dispute      │            0 │    15478 │
│ Prepaid      │            0 │       96 │
│ Way2ride     │           15 │       92 │
│ Mobile       │           15 │    32805 │
│ Unknown      │            2 │    93546 │
│ Cash         │            0 │ 14880127 │
│ Prcard       │            1 │    73698 │
│ Pcard        │            3 │     4997 │
│ No Charge    │            3 │   135208 │
│ Credit Card  │           17 │ 10830147 │
└──────────────┴──────────────┴──────────┘

10 rows in set. Elapsed: 4.559 sec. Processed 26.07 million rows, 832.95 MB (5.72 million rows/s., 182.69 MB/s.)
```
# 4 Выводы
- Выполнение команды COPY параллельно на нескольких ядрах не дает выигрыша в производительности при вставке данных в Postgresql. Вероятно, узким местом являются операции дискового ввода/вывода. 
- Выпонение эталонного запроса к таблице, содержащей 26 066 190 записей в PostgreSQL заняло 06 минут 29.572 секунд
- В результате оптимизации (анализ плана выполнения запроса и создание b-tree индекса) время выполнения запроса в PostgreSQL сократилось до 08.156 секунд
- Время выполнения эталонного запроса к таблице, содержащей 26 066 190 записей в ClickHouse составило 04.559 секунд. При этом оптимизация для сокращения времени запроса не проводилась.